run:
  samples: 1000 # Formely trajectories
  max_episodes: 1
  log_path: ''
  device: ''
  model: 'gpt-4-latest-C' #Running D3 again over all envs
  temperature: 0.7
  top_p: 0.95
  frequency_penalty: 0
  presence_penalty: 0
  stop: ""
  dynode_learning_rate: 1e-2
  rnn_learning_rate: 1e-2
  optimizer: 'pytorch' # 'evotorch-PGPE'
  keep_top_samples: 16
  reflection_history: 16
  sub_group_resample: 4
  generations: 20
  d3_patience: 20
  optimize_params: true
  optimization:
    patience: 100
    log_optimization: true
  pytorch_as_optimizer:
    batch_size: 1000
    learning_rate: 1e-2
    weight_decay: 0.0
    epochs: 2000
    log_interval: 10
  dynode_retrain_model: true
  dynode_saved_models_folder: 'saved_models/26012024'
setup:
  trajectories_sweep: [1, 10, 100]
  use_azure_api: true
  debug_mode: false
  flush_mode: false
  multi_process_results: false
  multi_process_cores: 4
  experiment: 'MAIN_TABLE'
  methods_to_evaluate: ['D3', 'ZeroShot', 'ZeroOptim', 'DyNODE', 'SINDY', 'Transformer', 'RNN']
  envs_to_evaluate: ['Cancer-untreated', 'Cancer-chemo', 'Cancer', 'Dataset-3DLV', 'Dataset-HL', 'COVID', 'warfarin']
  wandb:
    project: RealEnvGen
    track: false
  log_dir: logs
  torch_deterministic: true
  seed_start: 100
  seed_runs: 10
  enable_tests: false
  cuda: true
  data_science_env_use_description: false
  open_ai_rate_limit_requests_per_minute: 3000
  api_retry_with_exponential_backoff__initial_delay: 1
  api_retry_with_exponential_backoff__exponential_base: 2
  api_retry_with_exponential_backoff__jitter: true
  api_retry_with_exponential_backoff__max_retries: 10
  api_request_timeout: 60000
  api_stream: false
  force_recache: false
  load_from_cache: true